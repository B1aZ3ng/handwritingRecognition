{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 19:45:20.399872: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-08 19:45:20.409664: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-08 19:45:20.419960: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8473] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-08 19:45:20.423302: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1471] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-08 19:45:20.431985: I tensorflow/core/platform/cpu_feature_guard.cc:211] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../trainingData\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import images\n",
    "#--- words.txt ---------------------------------------------------------------#\n",
    "#\n",
    "# iam database word information\n",
    "#\n",
    "# format: a01-000u-00-00 ok 154 1 408 768 27 51 AT A\n",
    "#\n",
    "#     a01-000u-00-00  -> word id for line 00 in form a01-000u\n",
    "#     ok              -> result of word segmentation\n",
    "#                            ok: word was correctly\n",
    "#                            er: segmentation of word can be bad\n",
    "#\n",
    "#     154             -> graylevel to binarize the line containing this word\n",
    "#     1               -> number of components for this word NOTE: dont think this exists idk why\n",
    "#     408 768 27 51   -> bounding box around this word in x,y,w,h format\n",
    "#     AT              -> the grammatical tag for this word, see the\n",
    "#                        file tagset.txt for an explanation\n",
    "#     A               -> the transcription for this word\n",
    "#\n",
    "class img:\n",
    "    def __init__ (this,letter,p1,p2):\n",
    "        this.letter = letter\n",
    "        this.inPath = p1\n",
    "        this.savePath = p2\n",
    "    \n",
    "images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import directory for dataset 1 - IAM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To add a pixel of border around each picture, because zooming out uses the edge pixels\n",
    "def addBorder (path):\n",
    "    t = cv2.imread(dataPath+path+\".png\")\n",
    "    pic = np.array(t)\n",
    "    x,y,z = pic.shape #ALSO change colour here if needed\n",
    "    \n",
    "    column = np.array([[[255,255,255]] for i in range (x)]) # to add 1 pixel of white around the picture, because the picture is cropped to exactly where the side contains black and zoom function does not take that well\n",
    "    row = np.array([[[255,255,255] for i in range (y+2)]])\n",
    "    pic = np.concatenate([column,pic,column], axis=1)\n",
    "    pic = np.concatenate([row,pic,row],axis=0)\n",
    "    cv2.imwrite(dataPath+path+\".png\",pic)\n",
    "    return pic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18079\n"
     ]
    }
   ],
   "source": [
    "#import directory for dataset 1 - EMNIST\n",
    "images = []\n",
    "directory = open(dataPath + \"/ascii/words.txt\",\"r\").read().splitlines()\n",
    "len(directory)\n",
    "directory = directory[18:] #first 18 lines are instructions\n",
    "for i in directory:\n",
    "    data = i.split(\" \")\n",
    "    a = data[0].split(\"-\")\n",
    "    loc = \"/\"+a[0]+\"/\"+a[0]+\"-\"+a[1]+\"/\"+data[0]\n",
    "    letter = data[-1]\n",
    "    if len(letter) == 1:\n",
    "        images.append(img(letter,\"/words\"+loc,\"/IAM\"+loc))\n",
    "print(len(images))\n",
    "\n",
    "if open(\"log.txt\",\"r\").read() == \"\":\n",
    "    open(\"log.txt\",\"w\").write(\"added border\")\n",
    "    for img_ in images:\n",
    "        try:\n",
    "            addBorder(img_.inPath)\n",
    "        except:\n",
    "            print(dataPath+img_.inPath+\".png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/words/a01/a01-000u/a01-000u-00-00 ? /IAM/a01/a01-000u/a01-000u-00-00\n",
      "/words/a01/a01-000u/a01-000u-02-05 ? /IAM/a01/a01-000u/a01-000u-02-05\n",
      "/words/a01/a01-000u/a01-000u-03-02 ? /IAM/a01/a01-000u/a01-000u-03-02\n",
      "/words/a01/a01-000u/a01-000u-04-02 ? /IAM/a01/a01-000u/a01-000u-04-02\n",
      "/words/a01/a01-000u/a01-000u-06-01 ? /IAM/a01/a01-000u/a01-000u-06-01\n"
     ]
    }
   ],
   "source": [
    "for i in range (5):\n",
    "    print (images[i].inPath,letter,images[i].savePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg = ImageDataGenerator(zoom_range = [1,2],rotation_range = 30,width_shift_range=0.1,height_shift_range=0.1,horizontal_flip = True, vertical_flip = True)\n",
    "\n",
    "def augment (path,savePath):\n",
    "    # Converting the input sample image to an array\n",
    "    # Reshaping the input image\n",
    "    datagen = idg\n",
    "    # Loading a sample image \n",
    "    img = load_img(path) \n",
    "    # Converting the input sample image to an array\n",
    "    x = img_to_array(img)\n",
    "    # Reshaping the input image\n",
    "    x = x.reshape((1, ) + x.shape) \n",
    "    \n",
    "    # Generating and saving 5 augmented samples \n",
    "    # using the above defined parameters. \n",
    "    i = 0\n",
    "    if not os.path.exists(savePath):\n",
    "        os.makedirs(savePath)\n",
    "    else:\n",
    "        if len(os.listdir(savePath)) > 0:\n",
    "            return\n",
    "    for batch in datagen.flow(x, batch_size = 1,\n",
    "                            save_to_dir =savePath, \n",
    "                            save_prefix ='image', save_format ='jpeg'):\n",
    "        i += 1\n",
    "        if i >= 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#execute augment function, will take long time\n",
    "#change\n",
    "idg = ImageDataGenerator(zoom_range = [1,2],rotation_range = 30,width_shift_range=0.1,height_shift_range=0.1,horizontal_flip = True, vertical_flip = True,brightness_range=[0.5,1])\n",
    "\n",
    "last = \"\"\n",
    "total = len(images)\n",
    "last = 0\n",
    "imagesCopy = images.copy()\n",
    "count = len(open(\"progress.txt\",\"r\").read())\n",
    "progress = open(\"progress.txt\",\"a\")\n",
    "for i in tqdm (range(count,len(images))):\n",
    "    img_ = images[i]\n",
    "    count +=1\n",
    "    augment(dataPath+img_.inPath+\".png\",dataPath+\"/augmentedWords\"+img_.savePath)\n",
    "    progress.write(\".\")\n",
    "progress.close()\n",
    "open(\"progress.txt\",\"w\").close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#validation\n",
    "doesntWork = []\n",
    "for i in tqdm (range(count,len(images))):\n",
    "    img_ = images[i]\n",
    "    try:\n",
    "        a = os.listdir(dataPath+\"/augmentedWords\"+img_.savePath)\n",
    "        if len (a) < 5:\n",
    "            doesntWork.append(img_)\n",
    "    except:\n",
    "        doesntWork.append(img_)\n",
    "print (doesntWork)\n",
    "for img_ in doesntWork:\n",
    "    augment(dataPath+img_.inPath+\".png\",dataPath+\"/augmentedWords\"+img_.savePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18079\n"
     ]
    }
   ],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1545923\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "dir = os.listdir(dataPath + \"/by_class/\")\n",
    "for i in dir:\n",
    "    letter = chr(int(\"0x\"+i,0))\n",
    "    subDir = os.listdir(dataPath + \"/by_class/\"+i)\n",
    "    for j in subDir:\n",
    "        if j[-4:] != \".mit\":\n",
    "            imgDir = os.listdir(dataPath + \"/by_class/\"+i+\"/\"+j)\n",
    "            for k in imgDir:\n",
    "                images.append(img(letter,\"/by_class/\"+i+\"/\"+j+\"/\"+k[:-4],\"/EMNIST/\"+i+\"/\"+j+\"/\"+k[:-4]))\n",
    "\n",
    "print (len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████████████▍                                                                                                                                 | 219102/1545923 [25:59<2:42:54, 135.74it/s]"
     ]
    }
   ],
   "source": [
    "#execute augment function, will take long time\n",
    "#change\n",
    "idg = ImageDataGenerator(zoom_range = [0.4,0.8],rotation_range = 30,width_shift_range=0.1,height_shift_range=0.1,horizontal_flip = True, vertical_flip = True,brightness_range=[0.5,1])\n",
    "\n",
    "last = \"\"\n",
    "total = len(images)\n",
    "last = 0\n",
    "imagesCopy = images.copy()\n",
    "count = len(open(\"progress.txt\",\"r\").read())\n",
    "progress = open(\"progress.txt\",\"a\")\n",
    "for i in tqdm (range(count,len(images))):\n",
    "    img_ = images[i]\n",
    "    count +=1\n",
    "    augment(dataPath+img_.inPath+\".png\",dataPath+\"/augmentedWords\"+img_.savePath)\n",
    "    progress.write(\".\")\n",
    "progress.close()\n",
    "open(\"progress.txt\",\"w\").close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "doesntWork = []\n",
    "for i in tqdm (range(count,len(images))):\n",
    "    img_ = images[i]\n",
    "    try:\n",
    "        a = os.listdir(dataPath+\"/augmentedWords\"+img_.savePath)\n",
    "        if len (a) < 5:\n",
    "            doesntWork.append(img_)\n",
    "    except:\n",
    "        doesntWork.append(img_)\n",
    "print (doesntWork)\n",
    "for img_ in doesntWork:\n",
    "    augment(dataPath+img_.inPath+\".png\",dataPath+\"/augmentedWords\"+img_.savePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../trainingData\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import images\n",
    "#--- words.txt ---------------------------------------------------------------#\n",
    "#\n",
    "# iam database word information\n",
    "#\n",
    "# format: a01-000u-00-00 ok 154 1 408 768 27 51 AT A\n",
    "#\n",
    "#     a01-000u-00-00  -> word id for line 00 in form a01-000u\n",
    "#     ok              -> result of word segmentation\n",
    "#                            ok: word was correctly\n",
    "#                            er: segmentation of word can be bad\n",
    "#\n",
    "#     154             -> graylevel to binarize the line containing this word\n",
    "#     1               -> number of components for this word NOTE: dont think this exists idk why\n",
    "#     408 768 27 51   -> bounding box around this word in x,y,w,h format\n",
    "#     AT              -> the grammatical tag for this word, see the\n",
    "#                        file tagset.txt for an explanation\n",
    "#     A               -> the transcription for this word\n",
    "#\n",
    "class img:\n",
    "    def __init__ (this,letter,p1,p2):\n",
    "        this.letter = letter\n",
    "        this.inPath = p1\n",
    "        this.savePath = p2\n",
    "    \n",
    "images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import directory for dataset 1 - IAM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To add a pixel of border around each picture, because zooming out uses the edge pixels\n",
    "def addBorder (path):\n",
    "    t = cv2.imread(dataPath+path+\".png\")\n",
    "    pic = np.array(t)\n",
    "    x,y,z = pic.shape #ALSO change colour here if needed\n",
    "    \n",
    "    column = np.array([[[255,255,255]] for i in range (x)]) # to add 1 pixel of white around the picture, because the picture is cropped to exactly where the side contains black and zoom function does not take that well\n",
    "    row = np.array([[[255,255,255] for i in range (y+2)]])\n",
    "    pic = np.concatenate([column,pic,column], axis=1)\n",
    "    pic = np.concatenate([row,pic,row],axis=0)\n",
    "    cv2.imwrite(dataPath+path+\".png\",pic)\n",
    "    return pic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18079\n"
     ]
    }
   ],
   "source": [
    "#import directory for dataset 1 - EMNIST\n",
    "images = []\n",
    "directory = open(dataPath + \"/ascii/words.txt\",\"r\").read().splitlines()\n",
    "len(directory)\n",
    "directory = directory[18:] #first 18 lines are instructions\n",
    "for i in directory:\n",
    "    data = i.split(\" \")\n",
    "    a = data[0].split(\"-\")\n",
    "    loc = \"/\"+a[0]+\"/\"+a[0]+\"-\"+a[1]+\"/\"+data[0]\n",
    "    letter = data[-1]\n",
    "    if len(letter) == 1:\n",
    "        images.append(img(letter,\"/words\"+loc,\"/IAM\"+loc))\n",
    "print(len(images))\n",
    "\n",
    "if open(\"log.txt\",\"r\").read() == \"\":\n",
    "    open(\"log.txt\",\"w\").write(\"added border\")\n",
    "    for img_ in images:\n",
    "        try:\n",
    "            addBorder(img_.inPath)\n",
    "        except:\n",
    "            print(dataPath+img_.inPath+\".png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/words/a01/a01-000u/a01-000u-00-00 ? /IAM/a01/a01-000u/a01-000u-00-00\n",
      "/words/a01/a01-000u/a01-000u-02-05 ? /IAM/a01/a01-000u/a01-000u-02-05\n",
      "/words/a01/a01-000u/a01-000u-03-02 ? /IAM/a01/a01-000u/a01-000u-03-02\n",
      "/words/a01/a01-000u/a01-000u-04-02 ? /IAM/a01/a01-000u/a01-000u-04-02\n",
      "/words/a01/a01-000u/a01-000u-06-01 ? /IAM/a01/a01-000u/a01-000u-06-01\n"
     ]
    }
   ],
   "source": [
    "for i in range (5):\n",
    "    print (images[i].inPath,letter,images[i].savePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg = ImageDataGenerator(zoom_range = [1,2],rotation_range = 30,width_shift_range=0.1,height_shift_range=0.1,horizontal_flip = True, vertical_flip = True)\n",
    "\n",
    "def augment (path,savePath):\n",
    "    # Converting the input sample image to an array\n",
    "    # Reshaping the input image\n",
    "    datagen = idg\n",
    "    # Loading a sample image \n",
    "    img = load_img(path) \n",
    "    # Converting the input sample image to an array\n",
    "    x = img_to_array(img)\n",
    "    # Reshaping the input image\n",
    "    x = x.reshape((1, ) + x.shape) \n",
    "    \n",
    "    # Generating and saving 5 augmented samples \n",
    "    # using the above defined parameters. \n",
    "    i = 0\n",
    "    if not os.path.exists(savePath):\n",
    "        os.makedirs(savePath)\n",
    "    else:\n",
    "        if len(os.listdir(savePath)) > 0:\n",
    "            return\n",
    "    for batch in datagen.flow(x, batch_size = 1,\n",
    "                            save_to_dir =savePath, \n",
    "                            save_prefix ='image', save_format ='jpeg'):\n",
    "        i += 1\n",
    "        if i >= 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18079/18079 [00:34<00:00, 523.00it/s]\n"
     ]
    }
   ],
   "source": [
    "#execute augment function, will take long time\n",
    "#change\n",
    "idg = ImageDataGenerator(zoom_range = [1,2],rotation_range = 30,width_shift_range=0.1,height_shift_range=0.1,horizontal_flip = True, vertical_flip = True,brightness_range=[0.5,1])\n",
    "\n",
    "last = \"\"\n",
    "total = len(images)\n",
    "last = 0\n",
    "imagesCopy = images.copy()\n",
    "count = len(open(\"progress.txt\",\"r\").read())\n",
    "progress = open(\"progress.txt\",\"a\")\n",
    "for i in tqdm (range(count,len(images))):\n",
    "    img_ = images[i]\n",
    "    count +=1\n",
    "    augment(dataPath+img_.inPath+\".png\",dataPath+\"/augmentedWords\"+img_.savePath)\n",
    "    progress.write(\".\")\n",
    "progress.close()\n",
    "open(\"progress.txt\",\"w\").close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#validation\n",
    "doesntWork = []\n",
    "for i in tqdm (range(count,len(images))):\n",
    "    img_ = images[i]\n",
    "    try:\n",
    "        a = os.listdir(dataPath+\"/augmentedWords\"+img_.savePath)\n",
    "        if len (a) < 5:\n",
    "            doesntWork.append(img_)\n",
    "    except:\n",
    "        doesntWork.append(img_)\n",
    "print (doesntWork)\n",
    "for img_ in doesntWork:\n",
    "    augment(dataPath+img_.inPath+\".png\",dataPath+\"/augmentedWords\"+img_.savePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18079\n"
     ]
    }
   ],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1545923\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "dir = os.listdir(dataPath + \"/by_class/\")\n",
    "for i in dir:\n",
    "    letter = chr(int(\"0x\"+i,0))\n",
    "    subDir = os.listdir(dataPath + \"/by_class/\"+i)\n",
    "    for j in subDir:\n",
    "        if j[-4:] != \".mit\":\n",
    "            imgDir = os.listdir(dataPath + \"/by_class/\"+i+\"/\"+j)\n",
    "            for k in imgDir:\n",
    "                images.append(img(letter,\"/by_class/\"+i+\"/\"+j+\"/\"+k[:-4],\"/EMNIST/\"+i+\"/\"+j+\"/\"+k[:-4]))\n",
    "\n",
    "print (len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1545923/1545923 [3:04:25<00:00, 139.70it/s]\n"
     ]
    }
   ],
   "source": [
    "#execute augment function, will take long time\n",
    "#change\n",
    "idg = ImageDataGenerator(zoom_range = [0.4,0.8],rotation_range = 30,width_shift_range=0.1,height_shift_range=0.1,horizontal_flip = True, vertical_flip = True,brightness_range=[0.5,1])\n",
    "\n",
    "last = \"\"\n",
    "total = len(images)\n",
    "last = 0\n",
    "imagesCopy = images.copy()\n",
    "count = len(open(\"progress.txt\",\"r\").read())\n",
    "progress = open(\"progress.txt\",\"a\")\n",
    "for i in tqdm (range(count,len(images))):\n",
    "    img_ = images[i]\n",
    "    count +=1\n",
    "    augment(dataPath+img_.inPath+\".png\",dataPath+\"/augmentedWords\"+img_.savePath)\n",
    "    progress.write(\".\")\n",
    "progress.close()\n",
    "open(\"progress.txt\",\"w\").close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#validation\n",
    "doesntWork = []\n",
    "for i in tqdm (range(count,len(images))):\n",
    "    img_ = images[i]\n",
    "    try:\n",
    "        a = os.listdir(dataPath+\"/augmentedWords\"+img_.savePath)\n",
    "        if len (a) < 5:\n",
    "            doesntWork.append(img_)\n",
    "    except:\n",
    "        doesntWork.append(img_)\n",
    "print (doesntWork)\n",
    "for img_ in doesntWork:\n",
    "    augment(dataPath+img_.inPath+\".png\",dataPath+\"/augmentedWords\"+img_.savePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
